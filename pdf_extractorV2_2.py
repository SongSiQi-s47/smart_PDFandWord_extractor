import os
import re
import logging
import pdfplumber
import pandas as pd
from typing import List, Dict
from openpyxl.styles import Font, Alignment, Border, Side
from docx import Document
from collections import OrderedDict

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ±‰å­—æ•°å­—
CN_NUM = 'é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡äº¿ã€‡å£¹è´°åè‚†ä¼é™†æŸ’æŒç–æ‹¾'

def parse_sample_to_template(sample):
    template = []
    i = 0
    while i < len(sample):
        c = sample[i]
        if c.isdigit():
            num = c
            while i+1 < len(sample) and sample[i+1].isdigit():
                i += 1
                num += sample[i]
            template.append(('digit', num))
        elif c in CN_NUM:
            cn = c
            while i+1 < len(sample) and sample[i+1] in CN_NUM:
                i += 1
                cn += sample[i]
            template.append(('cndigit', cn))
        elif c in '()ï¼ˆï¼‰':
            template.append(('paren', c))
        elif c in 'ã€ã€‘':
            template.append(('bracket', c))
        elif c in '.ã€.':
            template.append(('sep', c))
        elif '\u4e00' <= c <= '\u9fa5':
            word = c
            while i+1 < len(sample) and '\u4e00' <= sample[i+1] <= '\u9fa5':
                i += 1
                word += sample[i]
            template.append(('ch', word))
        else:
            template.append(('other', c))
        i += 1
    return template

def template_to_regex(template):
    regex = ''
    for t, val in template:
        if t == 'digit':
            regex += r'\d+'
        elif t == 'cndigit':
            regex += f'[{CN_NUM}]+'
        elif t == 'paren':
            regex += re.escape(val)
        elif t == 'bracket':
            regex += re.escape(val)
        elif t == 'sep':
            regex += re.escape(val)
        elif t == 'ch':
            regex += f'.{{1,{len(val)+3}}}'
        else:
            regex += re.escape(val)
    return regex

def get_regex_from_sample(sample):
    template = parse_sample_to_template(sample)
    regex = template_to_regex(template)
    return re.compile(regex)

def get_fuzzy_regex_from_sample(sample):
    """
    ç”Ÿæˆæ›´çµæ´»çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ”¯æŒå„ç§ç¼–å·æ ¼å¼
    """
    # åŒ¹é…"æ•°å­—.æ•°å­—.æ•°å­—."ç»“æ„ï¼ˆå¦‚ 9.1.4.3.1.ï¼‰ï¼Œæ›´çµæ´»
    if re.match(r'^\d+(\.\d+)+\.?$', sample):
        # è¿”å›å¸¦åˆ†ç»„çš„æ­£åˆ™ï¼Œç¼–å·éƒ¨åˆ†æ›´çµæ´»ï¼Œæ”¯æŒæœ«å°¾æ²¡æœ‰ç‚¹çš„æƒ…å†µ
        # æ–°å¢ï¼šè®°å½•åŸå§‹æ ·ä¾‹çš„æ•°å­—é•¿åº¦ï¼Œç”¨äºåç»­é•¿åº¦æ£€æŸ¥
        sample_digits = re.sub(r'[^\d]', '', sample)
        regex = re.compile(r'^(\d+(?:\.\d+)+[\.\s\u3000ï¼ã€]*)(.*)$')
        # è¿”å›å­—å…¸ï¼ŒåŒ…å«æ­£åˆ™å’Œé•¿åº¦ä¿¡æ¯
        return {
            'regex': regex,
            'expected_digit_length': len(sample_digits)
        }
    
    # åŒ¹é…"æ•°å­—ï¼‰"æˆ–"æ•°å­—)"ç»“æ„ï¼ˆå¦‚ 1ï¼‰ æˆ– 1) ï¼‰ï¼Œæ”¯æŒä¸­è‹±æ–‡æ‹¬å·
    if re.match(r'^\d+[ï¼‰)]$', sample):
        return {
            'regex': re.compile(r'^(\d+[\)\ï¼‰])(.*)$'),
            'expected_digit_length': None
        }
    
    # åŒ¹é…"ï¼ˆæ•°å­—ï¼‰"æˆ–"(æ•°å­—)"ç»“æ„ï¼ˆå¦‚ ï¼ˆ1ï¼‰ æˆ– (1) ï¼‰ï¼Œæ”¯æŒä¸­è‹±æ–‡æ‹¬å·
    if re.match(r'^[ï¼ˆ(]\d+[ï¼‰)]$', sample):
        return {
            'regex': re.compile(r'^([ï¼ˆ(]\d+[\)\ï¼‰])(.*)$'),
            'expected_digit_length': None
        }
    
    # åŒ¹é…"ï¼ˆæ±‰å­—æ•°å­—ï¼‰"æˆ–"(æ±‰å­—æ•°å­—)"ç»“æ„ï¼ˆå¦‚ ï¼ˆåä¸€ï¼‰ æˆ– (åä¸€) ï¼‰ï¼Œæ”¯æŒæ›´å¤šæ±‰å­—æ•°å­—
    if re.match(r'^[ï¼ˆ(][é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡äº¿]+[ï¼‰)]$', sample):
        return {
            'regex': re.compile(r'^([ï¼ˆ(][é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡äº¿]+[\)\ï¼‰])(.*)$'),
            'expected_digit_length': None
        }
    
    # æ–°å¢ï¼šåŒ¹é…"æ•°å­—."ç»“æ„ï¼ˆå¦‚ 1.ï¼‰ï¼Œç”Ÿæˆæ›´ä¸¥æ ¼çš„æ­£åˆ™
    if re.match(r'^\d+\.$', sample):
        return {
            'regex': re.compile(r'^(\d+\.)(.*)$'),
            'expected_digit_length': None
        }
    
    # å…¶ä»–ç±»å‹ï¼šå…ˆå»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦ï¼ˆåŒ…æ‹¬å…¨è§’ç©ºæ ¼ï¼‰ï¼Œå†ç”¨æ¨¡æ¿è§£æç”Ÿæˆæ­£åˆ™
    sample = re.sub(r'[\s\u3000]', '', sample)
    template = parse_sample_to_template(sample)
    regex = template_to_regex(template)
    regex = regex.rstrip(r'\.')
    regex += r'[\.\s\u3000ï¼ã€]*'  # å…è®¸ç¼–å·åæœ‰ç‚¹ã€ç©ºæ ¼ã€é¡¿å·ç­‰
    return {
        'regex': re.compile(f'^({regex})(.*)$'),
        'expected_digit_length': None
    }

def smart_start_match(sample, text, regex):
    """
    æ™ºèƒ½èµ·å§‹ç¼–å·åŒ¹é…ï¼Œæ”¯æŒå¤šç§åŒ¹é…ç­–ç•¥
    """
    match = regex.match(text)
    if not match:
        return False, None, None
    
    # æå–æ•°å­—åºåˆ—
    sample_digits = re.sub(r'[^\d]', '', sample)
    text_number_part = match.group(1)
    text_digits = re.sub(r'[^\d]', '', text_number_part)
    
    # å¤šç§åŒ¹é…ç­–ç•¥
    if sample_digits == text_digits:
        return True, "å®Œå…¨åŒ¹é…", text_digits
    elif text_digits.startswith(sample_digits):
        return True, "å‰ç¼€åŒ¹é…", text_digits
    elif sample_digits.startswith(text_digits):
        # å‰ç¼€åŒ¹é…æ—¶æ£€æŸ¥é•¿åº¦æ˜¯å¦ä¸€è‡´
        if len(text_digits) == len(sample_digits):
            return True, "å‰ç¼€åŒ¹é…", text_digits
        else:
            return False, "å‰ç¼€é•¿åº¦ä¸åŒ¹é…", text_digits
    
    return False, "ä¸åŒ¹é…", text_digits

class PDFWordTableExtractor:
    def __init__(self):
        # é»˜è®¤çš„ç›®æ ‡åˆ—æ˜ å°„
        self.target_columns = {
            'åŠŸèƒ½æ¨¡å—': 'ä¸€çº§æ¨¡å—åç§°',
            'åŠŸèƒ½å­é¡¹': 'äºŒçº§æ¨¡å—åç§°',
            'ä¸‰çº§æ¨¡å—': 'ä¸‰çº§æ¨¡å—åç§°',
            'åŠŸèƒ½æè¿°': 'åŠŸèƒ½æè¿°'
        }
        
        # ç”¨æˆ·è‡ªå®šä¹‰çš„è¡¨å¤´æ˜ å°„ï¼ˆç”¨äºåˆåŒæ–‡ä»¶ï¼‰
        self.custom_headers = None
        
        # åˆå§‹åŒ–æå–çŠ¶æ€å˜é‡
        self.previous_lvl1_sample = None
        self.previous_lvl2_sample = None
        self.previous_lvl3_sample = None
        self.previous_end_sample = None
        self.previous_lvl1_regex = None
        self.previous_lvl2_regex = None
        self.previous_lvl3_regex = None
        self.previous_end_regex = None

    def extract_tables(self, file_path: str, file_type: str) -> List[Dict]:
        if file_type == "pdf":
            if "åˆåŒ" in file_path:
                return self.extract_tables_from_pdf_contract(file_path)
            else:
                return self.extract_tables_from_pdf_bid(file_path)
        elif file_type == "docx":
            if "åˆåŒ" in file_path:
                # å¯¹äºåˆåŒæ–‡ä»¶ï¼Œå…ˆè®¾ç½®è‡ªå®šä¹‰è¡¨å¤´
                if not self.custom_headers:
                    self.setup_custom_headers()
                return self.extract_tables_from_word_contract(file_path)
            else:
                return self.extract_tables_from_word_bid(file_path)
        else:
            print(f"æš‚ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path}")
            return []
            
    def setup_custom_headers(self):
        """è®¾ç½®ç”¨æˆ·è‡ªå®šä¹‰çš„è¡¨å¤´æ˜ å°„"""
        print("\n" + "="*50)
        print("ğŸ“‹ è¯·æ ¹æ®Wordæ–‡æ¡£ä¸­çš„å®é™…è¡¨å¤´è¾“å…¥å¯¹åº”çš„å­—æ®µå")
        print("="*50)
        print("æç¤ºï¼šå¦‚æœæŸä¸ªå­—æ®µåœ¨Wordæ–‡æ¡£ä¸­æ²¡æœ‰ï¼Œè¯·ç›´æ¥å›è½¦è·³è¿‡")
        print()
        
        custom_headers = {}
        
        # ä¸€çº§æ¨¡å—åç§°
        lvl1_header = input("è¯·è¾“å…¥Wordæ–‡æ¡£ä¸­å¯¹åº”'ä¸€çº§æ¨¡å—åç§°'çš„è¡¨å¤´ï¼ˆå¦‚ï¼šåŠŸèƒ½æ¨¡å—ã€æ¨¡å—åç§°ç­‰ï¼‰ï¼š").strip()
        if lvl1_header:
            custom_headers[lvl1_header] = 'ä¸€çº§æ¨¡å—åç§°'
        
        # äºŒçº§æ¨¡å—åç§°
        lvl2_header = input("è¯·è¾“å…¥Wordæ–‡æ¡£ä¸­å¯¹åº”'äºŒçº§æ¨¡å—åç§°'çš„è¡¨å¤´ï¼ˆå¦‚ï¼šåŠŸèƒ½å­é¡¹ã€å­æ¨¡å—ç­‰ï¼‰ï¼š").strip()
        if lvl2_header:
            custom_headers[lvl2_header] = 'äºŒçº§æ¨¡å—åç§°'
        
        # ä¸‰çº§æ¨¡å—åç§°
        lvl3_header = input("è¯·è¾“å…¥Wordæ–‡æ¡£ä¸­å¯¹åº”'ä¸‰çº§æ¨¡å—åç§°'çš„è¡¨å¤´ï¼ˆå¦‚ï¼šä¸‰çº§æ¨¡å—ã€å­é¡¹ç­‰ï¼‰ï¼š").strip()
        if lvl3_header:
            custom_headers[lvl3_header] = 'ä¸‰çº§æ¨¡å—åç§°'
        
        # åˆåŒæè¿°
        desc_header = input("è¯·è¾“å…¥Wordæ–‡æ¡£ä¸­å¯¹åº”'åˆåŒæè¿°'çš„è¡¨å¤´ï¼ˆå¦‚ï¼šåŠŸèƒ½æè¿°ã€æè¿°ã€å¤‡æ³¨ç­‰ï¼‰ï¼š").strip()
        if desc_header:
            custom_headers[desc_header] = 'åˆåŒæè¿°'
        
        if custom_headers:
            self.custom_headers = custom_headers
            print(f"\nâœ… å·²è®¾ç½®è‡ªå®šä¹‰è¡¨å¤´æ˜ å°„ï¼š")
            for word_header, standard_field in custom_headers.items():
                print(f"   {word_header} â†’ {standard_field}")
        else:
            print("\nâš ï¸ æœªè®¾ç½®ä»»ä½•è‡ªå®šä¹‰è¡¨å¤´ï¼Œå°†ä½¿ç”¨é»˜è®¤æ˜ å°„")
            self.custom_headers = None
        
        return custom_headers

    # ----------- PDF æ ‡ä¹¦ï¼ˆæ–°ç‰ˆåˆ†å±‚æå–ï¼‰ -----------
    def extract_tables_from_pdf_bid(self, pdf_path: str) -> List[Dict]:
        # æ¸…ç©ºä¹‹å‰çš„çŠ¶æ€å˜é‡
        def clear_previous_state():
            """æ¸…ç©ºä¹‹å‰çš„æå–çŠ¶æ€"""
            self.previous_lvl1_sample = None
            self.previous_lvl2_sample = None
            self.previous_lvl3_sample = None
            self.previous_end_sample = None
            self.previous_lvl1_regex = None
            self.previous_lvl2_regex = None
            self.previous_lvl3_regex = None
            self.previous_end_regex = None
            # print("DEBUG: å·²æ¸…ç©ºä¹‹å‰çš„æå–çŠ¶æ€")
        
        # è°ƒç”¨çŠ¶æ€æ¸…ç©º
        clear_previous_state()
        
        # æ–°å¢ï¼šé‡æ–°åˆ†ç±»æ¨¡å—å±‚çº§ï¼ˆç§»åˆ°å‡½æ•°å¼€å¤´ï¼‰
        def reclassify_module(text, current_level):
            """é‡æ–°åˆ†ç±»æ¨¡å—å±‚çº§"""
            if current_level == 3 and has_lvl3_sample:
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å½’ä¸ºäºŒçº§
                if lvl2_regex and lvl2_regex.match(text):
                    # if debug_enabled:
                    #     print(f"DEBUG: ä¸‰çº§æ¨¡å—é‡æ–°åˆ†ç±»ä¸ºäºŒçº§: '{text}'")
                    return 2
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å½’ä¸ºä¸€çº§
                elif lvl1_regex and lvl1_regex.match(text):
                    # if debug_enabled:
                    #     print(f"DEBUG: ä¸‰çº§æ¨¡å—é‡æ–°åˆ†ç±»ä¸ºä¸€çº§: '{text}'")
                    return 1
            
            elif current_level == 2 and not has_lvl3_sample:
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å½’ä¸ºä¸€çº§
                if lvl1_regex and lvl1_regex.match(text):
                    # if debug_enabled:
                    #     print(f"DEBUG: äºŒçº§æ¨¡å—é‡æ–°åˆ†ç±»ä¸ºä¸€çº§: '{text}'")
                    return 1
            
            return current_level
        
        # æ–°å¢ï¼šåˆ¤æ–­æ˜¯å¦å¯ç”¨é‡æ–°æ ¸éªŒï¼ˆç§»åˆ°å‡½æ•°å¼€å¤´ï¼‰
        def should_enable_verification():
            """åˆ¤æ–­æ˜¯å¦å¯ç”¨é‡æ–°æ ¸éªŒ"""
            if not lvl1_sample or not lvl2_sample:
                return False
            
            lvl1_len = len(lvl1_sample)
            lvl2_len = len(lvl2_sample)
            
            # ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœäºŒçº§æ ·ä¾‹åŒ…å«æ›´å¤šç‚¹å·ï¼Œè®¤ä¸ºäºŒçº§æ›´é•¿
            lvl1_dots = lvl1_sample.count('.')
            lvl2_dots = lvl2_sample.count('.')
            
            if lvl2_dots > lvl1_dots:
                # if debug_enabled:
                #     print(f"DEBUG: å¯ç”¨é‡æ–°æ ¸éªŒ - äºŒçº§ç‚¹å·({lvl2_dots}) > ä¸€çº§ç‚¹å·({lvl1_dots})")
                return True
            
            # ä¸€èˆ¬æƒ…å†µï¼šæ¯”è¾ƒå­—ç¬¦ä¸²é•¿åº¦
            if lvl2_len < lvl1_len:
                # if debug_enabled:
                #     print(f"DEBUG: å¯ç”¨é‡æ–°æ ¸éªŒ - äºŒçº§é•¿åº¦({lvl2_len}) < ä¸€çº§é•¿åº¦({lvl1_len})")
                return True
            
            return False
        
        # æ·»åŠ é¡µç è¿‡æ»¤å‡½æ•°
        def is_page_number(text):
            """åˆ¤æ–­æ˜¯å¦ä¸ºé¡µç ä¿¡æ¯"""
            page_patterns = [
                r'^ç¬¬\d+é¡µ$',
                r'^Page\s*\d+$',
                r'^-\s*\d+\s*-$',
            ]
            # æ›´ä¸¥æ ¼çš„çº¯æ•°å­—é¡µç åˆ¤æ–­
            if re.match(r'^\d+$', text.strip()):
                # å¦‚æœæ•°å­—å°äºç­‰äº3ä½æ•°ï¼Œä¸”å‰åæ²¡æœ‰å…¶ä»–å†…å®¹ï¼Œå¯èƒ½æ˜¯é¡µç 
                if len(text.strip()) <= 3:
                    return True
            return any(re.match(pattern, text.strip()) for pattern in page_patterns)
        
        print("è¯·è¾“å…¥å„çº§ç¼–å·æ ·ä¾‹ï¼ˆå¯å›è½¦è·³è¿‡äºŒçº§/ä¸‰çº§ï¼‰ï¼š")
        lvl1_sample = input("ä¸€çº§æ¨¡å—ç¼–å·æ ·ä¾‹ï¼ˆå¦‚9.1.3.4æˆ–ï¼ˆä¸€ï¼‰ï¼‰ï¼š").strip()
        lvl2_sample = input("äºŒçº§æ¨¡å—ç¼–å·æ ·ä¾‹ï¼ˆå¦‚9.1.3.4.1æˆ–ï¼ˆäºŒï¼‰ï¼Œå¯è·³è¿‡ï¼‰ï¼š").strip()
        lvl3_sample = input("ä¸‰çº§æ¨¡å—ç¼–å·æ ·ä¾‹ï¼ˆå¦‚1ï¼‰ï¼Œå¯è·³è¿‡ï¼‰ï¼š").strip()
        end_sample = input("ç»ˆæ­¢ç¼–å·æ ·ä¾‹ï¼ˆé‡åˆ°è¯¥ç¼–å·åœæ­¢æå–ï¼‰ï¼š").strip()

        lvl1_regex_info = get_fuzzy_regex_from_sample(lvl1_sample) if lvl1_sample else None
        lvl2_regex_info = get_fuzzy_regex_from_sample(lvl2_sample) if lvl2_sample else None
        lvl3_regex_info = get_fuzzy_regex_from_sample(lvl3_sample) if lvl3_sample else None
        end_regex_info = get_fuzzy_regex_from_sample(end_sample) if end_sample else None

        lvl1_regex = lvl1_regex_info['regex'] if lvl1_regex_info else None
        lvl2_regex = lvl2_regex_info['regex'] if lvl2_regex_info else None
        lvl3_regex = lvl3_regex_info['regex'] if lvl3_regex_info else None
        end_regex = end_regex_info['regex'] if end_regex_info else None

        results = []
        current_lvl1 = current_lvl2 = current_lvl3 = None
        last_lvl1 = last_lvl2 = last_lvl3 = None
        desc_lines = []
        extracting = False
        start_found = False
        in_lvl3 = False
        in_lvl2 = False

        lvl1_filled = False
        lvl2_filled = False
        lvl1_to_fill = ""
        lvl2_to_fill = ""

        # å…³é”®ï¼šåˆ¤æ–­æ˜¯å¦æœ‰ä¸‰çº§æ¨¡å—æ ·ä¾‹
        has_lvl3_sample = bool(lvl3_sample)

        # è¡¥å……å›æ¥ï¼šé¡µé¢å’Œè¡Œæ•°ç»Ÿè®¡
        page_count = 0
        line_count = 0
        
        # æ–°å¢ï¼šDEBUGæ§åˆ¶å˜é‡
        # debug_enabled = False

        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_num = page.page_number if hasattr(page, 'page_number') else pdf.pages.index(page)
                
                # è¡¥å……å›æ¥ï¼šé¡µé¢è®¡æ•°
                page_count += 1
                
                lines = (page.extract_text() or '').split('\n')
                for i, raw_text in enumerate(lines):
                    # è¡¥å……å›æ¥ï¼šè¡Œæ•°è®¡æ•°
                    line_count += 1
                    
                    # å¤„ç†åŸå§‹æ–‡æœ¬
                    text = re.sub(r'[\s\u3000]', '', raw_text)

                    # ç»ˆæ­¢ç¼–å·åˆ¤æ–­
                    if end_regex and end_regex.match(text):
                        is_match, match_type, actual_digits = smart_start_match(end_sample, text, end_regex)
                        if is_match:
                            # if debug_enabled:
                            #     print(f"DEBUG: è¯†åˆ«åˆ°ç»ˆæ­¢ç¼–å·: '{raw_text.strip()}'")
                            extracting = False
                            in_lvl3 = False
                            in_lvl2 = False
                            continue

                    # æ™ºèƒ½èµ·å§‹ç¼–å·åˆ¤æ–­
                    if not extracting and lvl1_sample and lvl1_regex and lvl1_regex.match(text):
                        is_match, match_type, actual_digits = smart_start_match(lvl1_sample, text, lvl1_regex)
                        if is_match:
                            extracting = True
                            start_found = True
                            # debug_enabled = True  # å¯ç”¨DEBUG
                            current_lvl1 = raw_text.strip()
                            lvl1_filled = False
                            lvl1_to_fill = current_lvl1
                            lvl2_to_fill = current_lvl2 if current_lvl2 else ""
                            in_lvl2 = False
                            # print(f"DEBUG: è¯†åˆ«åˆ°èµ·å§‹ç¼–å·ï¼Œå¼€å§‹æå– - ä¸€çº§æ¨¡å—: '{current_lvl1}'")

                    if not extracting:
                        continue

                    # å…ˆåˆ¤æ–­ä¸‰çº§
                    m3 = lvl3_regex.match(text) if lvl3_regex else None
                    if m3:
                        # if debug_enabled:
                        #     print(f"DEBUG: ä¸‰çº§æ¨¡å—åŒ¹é… - åŸå§‹æ–‡æœ¬: '{raw_text.strip()}', å¤„ç†å: '{text}'")
                        
                        # æ–°å¢ï¼šéªŒè¯ä¸‰çº§æ¨¡å—åŒ¹é…çš„æœ‰æ•ˆæ€§
                        def is_valid_lvl3_match(match_obj, original_text):
                            """éªŒè¯ä¸‰çº§æ¨¡å—åŒ¹é…æ˜¯å¦æœ‰æ•ˆ"""
                            if not match_obj:
                                return False
                            
                            # æå–åŒ¹é…çš„ç¼–å·éƒ¨åˆ†
                            number_part = match_obj.group(1)
                            title_part = match_obj.group(2).strip()
                            
                            # if debug_enabled:
                            #     print(f"DEBUG: ä¸‰çº§æ¨¡å—éªŒè¯ - ç¼–å·éƒ¨åˆ†: '{number_part}', æ ‡é¢˜éƒ¨åˆ†: '{title_part}'")
                            
                            # æ£€æŸ¥æ ‡é¢˜éƒ¨åˆ†æ˜¯å¦æœ‰å†…å®¹
                            if not title_part:
                                # if debug_enabled:
                                #     print(f"DEBUG: ä¸‰çº§æ¨¡å—æ ‡é¢˜ä¸ºç©º: '{original_text}'")
                                return False
                            
                            return True
                        
                        # éªŒè¯åŒ¹é…æœ‰æ•ˆæ€§
                        if not is_valid_lvl3_match(m3, raw_text.strip()):
                            # if debug_enabled:
                            #     print(f"DEBUG: ä¸‰çº§æ¨¡å—éªŒè¯å¤±è´¥ï¼Œè®¾ä¸ºNone")
                            m3 = None
                        
                        if lvl3_regex_info and lvl3_regex_info['expected_digit_length']:
                            text_digits = re.sub(r'[^\d]', '', m3.group(1))
                            if len(text_digits) != lvl3_regex_info['expected_digit_length']:
                                                            # if debug_enabled:
                            #     print(f"DEBUG: ä¸‰çº§æ¨¡å—æ•°å­—é•¿åº¦ä¸åŒ¹é…: æœŸæœ›{lvl3_regex_info['expected_digit_length']}, å®é™…{len(text_digits)}")
                                m3 = None

                        if m3:
                            # if debug_enabled:
                            #     print(f"DEBUG: ç¡®è®¤ä¸‰çº§æ¨¡å—åŒ¹é…æˆåŠŸ")
                            
                            # æ–°å¢ï¼šé‡æ–°æ ¸éªŒé€»è¾‘
                            if should_enable_verification():
                                new_level = reclassify_module(raw_text.strip(), 3)
                                if new_level != 3:
                                    # é‡æ–°åˆ†ç±»ï¼Œè·³è¿‡ä¸‰çº§æ¨¡å—å¤„ç†
                                    m3 = None
                                    # if debug_enabled:
                                    #     print(f"DEBUG: ä¸‰çº§æ¨¡å—é‡æ–°åˆ†ç±»ä¸º{new_level}çº§ï¼Œè·³è¿‡ä¸‰çº§å¤„ç†")
                            
                            if m3:  # å¦‚æœæ²¡æœ‰é‡æ–°åˆ†ç±»ï¼Œç»§ç»­æ­£å¸¸å¤„ç†
                                # é‡åˆ°æ–°ä¸‰çº§ç¼–å·æ—¶ï¼Œå…ˆè¾“å‡ºä¸Šä¸€ç»„ï¼ˆå¦‚æœæœ‰æè¿°ï¼‰
                                if in_lvl3 and desc_lines:
                                    results.append({
                                        "ä¸€çº§æ¨¡å—åç§°": lvl1_to_fill,
                                        "äºŒçº§æ¨¡å—åç§°": lvl2_to_fill,
                                        "ä¸‰çº§æ¨¡å—åç§°": last_lvl3,
                                        "æ ‡ä¹¦æè¿°": '\n\n'.join(self._merge_paragraphs(desc_lines)).strip(),
                                        "åˆåŒæè¿°": "",
                                        "æ¥æºæ–‡ä»¶": os.path.basename(pdf_path),
                                        # "é¡µç ": page_count
                                    })
                                    desc_lines = []
                                    lvl1_filled = True
                                    lvl2_filled = True

                                number = m3.group(1)
                                title = m3.group(2).strip()
                                current_lvl3 = f"{number} {title}".strip()
                                last_lvl3 = current_lvl3
                                in_lvl3 = True
                                in_lvl2 = False
                                lvl1_to_fill = current_lvl1 if not lvl1_filled else ""
                                lvl2_to_fill = current_lvl2 if not lvl2_filled else ""
                                # if debug_enabled:
                                #     print(f"DEBUG: è®¾ç½®ä¸‰çº§æ¨¡å—: '{current_lvl3}'")
                                continue
                    elif lvl3_regex and lvl3_regex.match(text):
                        pass
                        # if debug_enabled:
                        #     print(f"DEBUG: æ­£åˆ™åŒ¹é…ä½†è¢«è¿‡æ»¤ - åŸå§‹æ–‡æœ¬: '{raw_text.strip()}', å¤„ç†å: '{text}'")

                    # å†åˆ¤æ–­äºŒçº§
                    m2 = lvl2_regex.match(text) if lvl2_regex else None
                    if m2:
                        # if debug_enabled:
                        #     print(f"DEBUG: äºŒçº§æ¨¡å—åŒ¹é… - åŸå§‹æ–‡æœ¬: '{raw_text.strip()}', å¤„ç†å: '{text}'")
                        
                        # æ–°å¢ï¼šäºŒçº§æ¨¡å—é•¿åº¦éªŒè¯
                        def is_valid_lvl2_match(match_obj, original_text):
                            """éªŒè¯äºŒçº§æ¨¡å—åŒ¹é…æ˜¯å¦æœ‰æ•ˆ"""
                            if not match_obj:
                                return False
                            
                            # æå–åŒ¹é…çš„ç¼–å·éƒ¨åˆ†
                            number_part = match_obj.group(1)
                            title_part = match_obj.group(2).strip()
                            
                            # é•¿åº¦æ¯”è¾ƒéªŒè¯
                            def check_lvl2_length_compatibility():
                                """æ£€æŸ¥äºŒçº§æ¨¡å—æ ·ä¾‹é•¿åº¦ä¸åŒ¹é…å†…å®¹çš„å…¼å®¹æ€§"""
                                if not lvl2_sample:
                                    return True
                                
                                # åªåœ¨äºŒçº§æ¨¡å—æ ·ä¾‹æ˜¯ç®€å•æ•°å­—æ ¼å¼æ—¶æ‰å¯ç”¨é•¿åº¦åˆ¤æ–­
                                def is_simple_number_format(sample):
                                    """åˆ¤æ–­æ˜¯å¦ä¸ºç®€å•æ•°å­—æ ¼å¼"""
                                    # åŒ¹é… "1."ã€"1ï¼‰"ã€"1)"ã€"1ã€" ç­‰ç®€å•æ ¼å¼
                                    simple_patterns = [
                                        r'^\d+\.$',      # 1.
                                        r'^\d+[ï¼‰)]$',   # 1ï¼‰ æˆ– 1)
                                        r'^\d+ã€$',      # 1ã€
                                        r'^\d+ã€‘$',      # 1ã€‘
                                        r'^\d+]$',       # 1]
                                    ]
                                    return any(re.match(pattern, sample) for pattern in simple_patterns)
                                
                                # å¦‚æœä¸æ˜¯ç®€å•æ•°å­—æ ¼å¼ï¼Œè·³è¿‡é•¿åº¦æ¯”è¾ƒ
                                if not is_simple_number_format(lvl2_sample):
                                    # if debug_enabled:
                                    #     print(f"DEBUG: äºŒçº§æ ·ä¾‹ä¸æ˜¯ç®€å•æ•°å­—æ ¼å¼ï¼Œè·³è¿‡é•¿åº¦æ¯”è¾ƒ: '{lvl2_sample}'")
                                    return True
                                
                                # æå–æ ·ä¾‹ä¸­çš„æ•°å­—é•¿åº¦
                                sample_digits = re.sub(r'[^\d]', '', lvl2_sample)
                                sample_digit_length = len(sample_digits)
                                
                                # æå–åŒ¹é…å†…å®¹ä¸­çš„æ•°å­—é•¿åº¦
                                match_digits = re.sub(r'[^\d]', '', number_part)
                                match_digit_length = len(match_digits)
                                
                                # if debug_enabled:
                                #     print(f"DEBUG: äºŒçº§é•¿åº¦æ¯”è¾ƒ - æ ·ä¾‹æ•°å­—é•¿åº¦: {sample_digit_length}, åŒ¹é…æ•°å­—é•¿åº¦: {match_digit_length}")
                                
                                # å¦‚æœåŒ¹é…çš„æ•°å­—é•¿åº¦æ˜æ˜¾å¤§äºæ ·ä¾‹ï¼Œå¯èƒ½æ˜¯è¯¯åŒ¹é…
                                if match_digit_length > sample_digit_length + 2:  # å…è®¸2ä½æ•°å­—çš„è¯¯å·®
                                    # if debug_enabled:
                                    #     print(f"DEBUG: äºŒçº§é•¿åº¦ä¸åŒ¹é…ï¼Œå¯èƒ½æ˜¯è¯¯åŒ¹é… - æ ·ä¾‹: '{lvl2_sample}', åŒ¹é…: '{number_part}'")
                                    return False
                                
                                return True
                            
                            # æ£€æŸ¥æ ‡é¢˜éƒ¨åˆ†æ˜¯å¦æœ‰å†…å®¹
                            if not title_part:
                                # if debug_enabled:
                                #     print(f"DEBUG: äºŒçº§æ¨¡å—æ ‡é¢˜ä¸ºç©º: '{original_text}'")
                                return False
                            
                            # æ‰§è¡Œé•¿åº¦æ¯”è¾ƒéªŒè¯
                            if not check_lvl2_length_compatibility():
                                return False
                            
                            return True
                        
                        # éªŒè¯äºŒçº§æ¨¡å—åŒ¹é…æœ‰æ•ˆæ€§
                        if not is_valid_lvl2_match(m2, raw_text.strip()):
                            # if debug_enabled:
                            #     print(f"DEBUG: äºŒçº§æ¨¡å—éªŒè¯å¤±è´¥ï¼Œè®¾ä¸ºNone")
                            m2 = None
                        
                        if lvl2_regex_info and lvl2_regex_info['expected_digit_length']:
                            text_digits = re.sub(r'[^\d]', '', m2.group(1))
                            if len(text_digits) != lvl2_regex_info['expected_digit_length']:
                                # if debug_enabled:
                                #     print(f"DEBUG: äºŒçº§æ¨¡å—æ•°å­—é•¿åº¦ä¸åŒ¹é…: æœŸæœ›{lvl2_regex_info['expected_digit_length']}, å®é™…{len(text_digits)}")
                                m2 = None
                        if m2:
                            # if debug_enabled:
                            #     print(f"DEBUG: ç¡®è®¤äºŒçº§æ¨¡å—åŒ¹é…æˆåŠŸ")
                            
                            # æ–°å¢ï¼šé‡æ–°æ ¸éªŒé€»è¾‘ï¼ˆæ²¡æœ‰ä¸‰çº§æ ·ä¾‹æ—¶ï¼‰
                            if not has_lvl3_sample and should_enable_verification():
                                new_level = reclassify_module(raw_text.strip(), 2)
                                if new_level != 2:
                                    # é‡æ–°åˆ†ç±»ï¼Œè·³è¿‡äºŒçº§æ¨¡å—å¤„ç†
                                    m2 = None
                                    # if debug_enabled:
                                    #     print(f"DEBUG: äºŒçº§æ¨¡å—é‡æ–°åˆ†ç±»ä¸º{new_level}çº§ï¼Œè·³è¿‡äºŒçº§å¤„ç†")
                            
                            if m2:  # å¦‚æœæ²¡æœ‰é‡æ–°åˆ†ç±»ï¼Œç»§ç»­æ­£å¸¸å¤„ç†
                                # æ ¹æ®æ˜¯å¦æœ‰ä¸‰çº§æ¨¡å—ä½¿ç”¨ä¸åŒé€»è¾‘
                                if has_lvl3_sample:
                                    # æœ‰ä¸‰çº§æ¨¡å—æ ·ä¾‹ï¼šä½¿ç”¨è€ä»£ç é€»è¾‘
                                    if in_lvl3 and desc_lines:
                                        results.append({
                                            "ä¸€çº§æ¨¡å—åç§°": lvl1_to_fill,
                                            "äºŒçº§æ¨¡å—åç§°": lvl2_to_fill,
                                            "ä¸‰çº§æ¨¡å—åç§°": last_lvl3,
                                            "æ ‡ä¹¦æè¿°": '\n\n'.join(self._merge_paragraphs(desc_lines)).strip()
                                        })
                                        desc_lines = []
                                        lvl1_filled = True
                                        lvl2_filled = True
                                        in_lvl3 = False
                                    number = m2.group(1)
                                    title = m2.group(2).strip()
                                    current_lvl2 = f"{number} {title}".strip()
                                    current_lvl3 = None
                                    last_lvl2 = current_lvl2
                                    lvl2_filled = False
                                    in_lvl2 = True
                                    in_lvl3 = False
                                    
                                    # æ›´æ–°å¡«å……å€¼
                                    lvl1_to_fill = current_lvl1 if not lvl1_filled else ""
                                    lvl2_to_fill = current_lvl2
                                    # if debug_enabled:
                                    #     print(f"DEBUG: è®¾ç½®äºŒçº§æ¨¡å—: '{current_lvl2}'")
                                    continue

                                else:
                                    # æ²¡æœ‰ä¸‰çº§æ¨¡å—æ ·ä¾‹ï¼šä½¿ç”¨æ–°ä»£ç é€»è¾‘
                                    # å¦‚æœä¹‹å‰æœ‰æè¿°å†…å®¹ï¼Œå…ˆè¾“å‡ºä¸Šä¸€ç»„
                                    if desc_lines and in_lvl2 and last_lvl2:
                                        results.append({
                                            "ä¸€çº§æ¨¡å—åç§°": lvl1_to_fill,
                                            "äºŒçº§æ¨¡å—åç§°": last_lvl2,  # ä½¿ç”¨ä¸Šä¸€ä¸ªäºŒçº§æ¨¡å—åç§°
                                            "ä¸‰çº§æ¨¡å—åç§°": "",
                                            "æ ‡ä¹¦æè¿°": '\n\n'.join(self._merge_paragraphs(desc_lines)).strip()
                                        })
                                        desc_lines = []
                                        lvl1_filled = True
                                        lvl2_filled = True
                                    
                                    # æ›´æ–°å½“å‰äºŒçº§æ¨¡å—
                                    number = m2.group(1)
                                    title = m2.group(2).strip()
                                    current_lvl2 = f"{number} {title}".strip()
                                    current_lvl3 = None
                                    last_lvl2 = current_lvl2
                                    lvl2_filled = False
                                    in_lvl2 = True
                                    in_lvl3 = False
                                    
                                    # æ›´æ–°å¡«å……å€¼
                                    lvl1_to_fill = current_lvl1 if not lvl1_filled else ""
                                    lvl2_to_fill = current_lvl2

                                    if in_lvl3 and desc_lines:
                                        results.append({
                                            "ä¸€çº§æ¨¡å—åç§°": lvl1_to_fill,
                                            "äºŒçº§æ¨¡å—åç§°": lvl2_to_fill,
                                            "ä¸‰çº§æ¨¡å—åç§°": last_lvl3,
                                            "æ ‡ä¹¦æè¿°": '\n\n'.join(self._merge_paragraphs(desc_lines)).strip()
                                        })
                                        desc_lines = []
                                        lvl1_filled = True
                                        lvl2_filled = True
                                        in_lvl3 = False
                                    # if debug_enabled:
                                    #     print(f"DEBUG: è®¾ç½®äºŒçº§æ¨¡å—: '{current_lvl2}'")
                                    continue

                    # æœ€ååˆ¤æ–­ä¸€çº§
                    m1 = lvl1_regex.match(text) if lvl1_regex else None
                    if m1:
                        # if debug_enabled:
                        #     print(f"DEBUG: ä¸€çº§æ¨¡å—åŒ¹é… - åŸå§‹æ–‡æœ¬: '{raw_text.strip()}', å¤„ç†å: '{text}'")
                        
                        # æ–°å¢ï¼šä¸€çº§æ¨¡å—é•¿åº¦éªŒè¯
                        def is_valid_lvl1_match(match_obj, original_text):
                            """éªŒè¯ä¸€çº§æ¨¡å—åŒ¹é…æ˜¯å¦æœ‰æ•ˆ"""
                            if not match_obj:
                                return False
                            
                            # æå–åŒ¹é…çš„ç¼–å·éƒ¨åˆ†
                            number_part = match_obj.group(1)
                            title_part = match_obj.group(2).strip()
                            
                            # é•¿åº¦æ¯”è¾ƒéªŒè¯
                            def check_lvl1_length_compatibility():
                                """æ£€æŸ¥ä¸€çº§æ¨¡å—æ ·ä¾‹é•¿åº¦ä¸åŒ¹é…å†…å®¹çš„å…¼å®¹æ€§"""
                                if not lvl1_sample:
                                    return True
                                
                                # åªåœ¨ä¸€çº§æ¨¡å—æ ·ä¾‹æ˜¯ç®€å•æ•°å­—æ ¼å¼æ—¶æ‰å¯ç”¨é•¿åº¦åˆ¤æ–­
                                def is_simple_number_format(sample):
                                    """åˆ¤æ–­æ˜¯å¦ä¸ºç®€å•æ•°å­—æ ¼å¼"""
                                    # åŒ¹é… "1."ã€"1ï¼‰"ã€"1)"ã€"1ã€" ç­‰ç®€å•æ ¼å¼
                                    simple_patterns = [
                                        r'^\d+\.$',      # 1.
                                        r'^\d+[ï¼‰)]$',   # 1ï¼‰ æˆ– 1)
                                        r'^\d+ã€$',      # 1ã€
                                        r'^\d+ã€‘$',      # 1ã€‘
                                        r'^\d+]$',       # 1]
                                    ]
                                    return any(re.match(pattern, sample) for pattern in simple_patterns)
                                
                                # å¦‚æœä¸æ˜¯ç®€å•æ•°å­—æ ¼å¼ï¼Œè·³è¿‡é•¿åº¦æ¯”è¾ƒ
                                if not is_simple_number_format(lvl1_sample):
                                    # if debug_enabled:
                                    #     print(f"DEBUG: ä¸€çº§æ ·ä¾‹ä¸æ˜¯ç®€å•æ•°å­—æ ¼å¼ï¼Œè·³è¿‡é•¿åº¦æ¯”è¾ƒ: '{lvl1_sample}'")
                                    return True
                                
                                # æå–æ ·ä¾‹ä¸­çš„æ•°å­—é•¿åº¦
                                sample_digits = re.sub(r'[^\d]', '', lvl1_sample)
                                sample_digit_length = len(sample_digits)
                                
                                # æå–åŒ¹é…å†…å®¹ä¸­çš„æ•°å­—é•¿åº¦
                                match_digits = re.sub(r'[^\d]', '', number_part)
                                match_digit_length = len(match_digits)
                                
                                # if debug_enabled:
                                #     print(f"DEBUG: ä¸€çº§é•¿åº¦æ¯”è¾ƒ - æ ·ä¾‹æ•°å­—é•¿åº¦: {sample_digit_length}, åŒ¹é…æ•°å­—é•¿åº¦: {match_digit_length}")
                                
                                # å¦‚æœåŒ¹é…çš„æ•°å­—é•¿åº¦æ˜æ˜¾å¤§äºæ ·ä¾‹ï¼Œå¯èƒ½æ˜¯è¯¯åŒ¹é…
                                if match_digit_length > sample_digit_length + 2:  # å…è®¸2ä½æ•°å­—çš„è¯¯å·®
                                    # if debug_enabled:
                                    #     print(f"DEBUG: ä¸€çº§é•¿åº¦ä¸åŒ¹é…ï¼Œå¯èƒ½æ˜¯è¯¯åŒ¹é… - æ ·ä¾‹: '{lvl1_sample}', åŒ¹é…: '{number_part}'")
                                    return False
                                
                                return True
                            
                            # æ£€æŸ¥æ ‡é¢˜éƒ¨åˆ†æ˜¯å¦æœ‰å†…å®¹
                            if not title_part:
                                # if debug_enabled:
                                #     print(f"DEBUG: ä¸€çº§æ¨¡å—æ ‡é¢˜ä¸ºç©º: '{original_text}'")
                                return False
                            
                            # æ‰§è¡Œé•¿åº¦æ¯”è¾ƒéªŒè¯
                            if not check_lvl1_length_compatibility():
                                return False
                            
                            return True
                        
                        # éªŒè¯ä¸€çº§æ¨¡å—åŒ¹é…æœ‰æ•ˆæ€§
                        if not is_valid_lvl1_match(m1, raw_text.strip()):
                            # if debug_enabled:
                            #     print(f"DEBUG: ä¸€çº§æ¨¡å—éªŒè¯å¤±è´¥ï¼Œè®¾ä¸ºNone")
                            m1 = None
                        
                        if lvl1_regex_info and lvl1_regex_info['expected_digit_length']:
                            text_digits = re.sub(r'[^\d]', '', m1.group(1))
                            if len(text_digits) != lvl1_regex_info['expected_digit_length']:
                                # if debug_enabled:
                                #     print(f"DEBUG: ä¸€çº§æ¨¡å—æ•°å­—é•¿åº¦ä¸åŒ¹é…: æœŸæœ›{lvl1_regex_info['expected_digit_length']}, å®é™…{len(text_digits)}")
                                m1 = None
                        if m1:
                            # if debug_enabled:
                            #     print(f"DEBUG: ç¡®è®¤ä¸€çº§æ¨¡å—åŒ¹é…æˆåŠŸ")
                            # æ ¹æ®æ˜¯å¦æœ‰ä¸‰çº§æ¨¡å—ä½¿ç”¨ä¸åŒé€»è¾‘
                            if has_lvl3_sample:
                                # æœ‰ä¸‰çº§æ¨¡å—æ ·ä¾‹ï¼šä½¿ç”¨è€ä»£ç é€»è¾‘
                                if in_lvl3 and desc_lines:
                                    results.append({
                                        "ä¸€çº§æ¨¡å—åç§°": lvl1_to_fill,
                                        "äºŒçº§æ¨¡å—åç§°": lvl2_to_fill,
                                        "ä¸‰çº§æ¨¡å—åç§°": last_lvl3,
                                        "æ ‡ä¹¦æè¿°": '\n\n'.join(self._merge_paragraphs(desc_lines)).strip(),
                                        "åˆåŒæè¿°": "",
                                        "æ¥æºæ–‡ä»¶": os.path.basename(pdf_path),
                                        # "é¡µç ": page_count
                                    })
                                    desc_lines = []
                                    lvl1_filled = True
                                    lvl2_filled = True
                                    in_lvl3 = False
                            else:
                                # æ²¡æœ‰ä¸‰çº§æ¨¡å—æ ·ä¾‹ï¼šä½¿ç”¨æ–°ä»£ç é€»è¾‘
                                if desc_lines and not in_lvl3:
                                    results.append({
                                        "ä¸€çº§æ¨¡å—åç§°": lvl1_to_fill,
                                        "äºŒçº§æ¨¡å—åç§°": lvl2_to_fill,
                                        "ä¸‰çº§æ¨¡å—åç§°": "",
                                        "æ ‡ä¹¦æè¿°": '\n\n'.join(self._merge_paragraphs(desc_lines)).strip(),
                                        "åˆåŒæè¿°": "",
                                        "æ¥æºæ–‡ä»¶": os.path.basename(pdf_path),
                                        # "é¡µç ": page_count
                                    })
                                    desc_lines = []
                                    lvl1_filled = True
                                    lvl2_filled = True

                                if in_lvl3 and desc_lines:
                                    results.append({
                                        "ä¸€çº§æ¨¡å—åç§°": lvl1_to_fill,
                                        "äºŒçº§æ¨¡å—åç§°": lvl2_to_fill,
                                        "ä¸‰çº§æ¨¡å—åç§°": last_lvl3,
                                        "æ ‡ä¹¦æè¿°": '\n\n'.join(self._merge_paragraphs(desc_lines)).strip(),
                                        "åˆåŒæè¿°": "",
                                        "æ¥æºæ–‡ä»¶": os.path.basename(pdf_path),
                                        # "é¡µç ": page_count
                                    })
                                    desc_lines = []
                                    lvl1_filled = True
                                    lvl2_filled = True
                                    in_lvl3 = False

                            number = m1.group(1)
                            title = m1.group(2).strip()
                            current_lvl1 = f"{number} {title}".strip()
                            current_lvl2 = current_lvl3 = None
                            last_lvl1 = current_lvl1
                            lvl1_filled = False
                            lvl2_filled = False
                            in_lvl2 = False
                            in_lvl3 = False
                            lvl1_to_fill = current_lvl1
                            lvl2_to_fill = current_lvl2 if current_lvl2 else ""
                            # if debug_enabled:
                            #     print(f"DEBUG: è®¾ç½®ä¸€çº§æ¨¡å—: '{current_lvl1}'")
                            continue

                    # ä¿®æ”¹åçš„æ”¶é›†é€»è¾‘ - å…³é”®ä¿®å¤
                    if extracting:
                        # æ–°å¢ï¼šæ›´ä¸¥æ ¼çš„æè¿°æ”¶é›†éªŒè¯
                        def should_collect_description():
                            """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ”¶é›†æè¿°å†…å®¹"""
                            # å¦‚æœæœ‰ä¸‰çº§æ¨¡å—æ ·ä¾‹
                            if has_lvl3_sample:
                                # åªæœ‰åœ¨ä¸‰çº§æ¨¡å—ä¸‹æ‰æ”¶é›†
                                return in_lvl3
                            else:
                                # æ²¡æœ‰ä¸‰çº§æ¨¡å—æ ·ä¾‹æ—¶
                                if in_lvl2:
                                    return True
                                # elif current_lvl1 and not current_lvl2:
                                #    return True
                                return False
                        
                        # åªæœ‰åœ¨åº”è¯¥æ”¶é›†çš„æƒ…å†µä¸‹æ‰æ·»åŠ æè¿°
                        if should_collect_description():
                            # é¢å¤–éªŒè¯ï¼šç¡®ä¿ä¸æ˜¯æ¨¡å—æ ‡é¢˜è¡Œ
                            if not (lvl1_regex and lvl1_regex.match(text)) and \
                               not (lvl2_regex and lvl2_regex.match(text)) and \
                               not (lvl3_regex and lvl3_regex.match(text)):
                                desc_lines.append(raw_text.strip())
                        else:
                            pass

        # è¡¥å……æœ€åä¸€ç»„
        if in_lvl3 and desc_lines:
            results.append({
                "ä¸€çº§æ¨¡å—åç§°": lvl1_to_fill,
                "äºŒçº§æ¨¡å—åç§°": lvl2_to_fill,
                "ä¸‰çº§æ¨¡å—åç§°": last_lvl3,
                "æ ‡ä¹¦æè¿°": '\n\n'.join(self._merge_paragraphs(desc_lines)).strip(),
                "åˆåŒæè¿°": "",
                "æ¥æºæ–‡ä»¶": os.path.basename(pdf_path),
                # "é¡µç ": page_count
            })
        elif desc_lines:  # å¦‚æœæ²¡æœ‰ä¸‰çº§æ¨¡å—ä½†æœ‰æè¿°å†…å®¹
            # ç¡®ä¿æœ‰æ­£ç¡®çš„äºŒçº§æ¨¡å—åç§°
            final_lvl2 = last_lvl2 if last_lvl2 else current_lvl2 if current_lvl2 else lvl2_to_fill
            results.append({
                "ä¸€çº§æ¨¡å—åç§°": current_lvl1 if current_lvl1 else lvl1_to_fill,
                "äºŒçº§æ¨¡å—åç§°": final_lvl2,
                "ä¸‰çº§æ¨¡å—åç§°": "",
                "æ ‡ä¹¦æè¿°": '\n\n'.join(self._merge_paragraphs(desc_lines)).strip(),
                "åˆåŒæè¿°": "",
                "æ¥æºæ–‡ä»¶": os.path.basename(pdf_path),
                # "é¡µç ": page_count
            })

        # æ¸…ç†æ•°æ® - æš‚æ—¶æ³¨é‡Šæ‰
        # results = self._clean_extracted_data(results)
        results = [r for r in results if any([r["ä¸€çº§æ¨¡å—åç§°"], r["äºŒçº§æ¨¡å—åç§°"], r["ä¸‰çº§æ¨¡å—åç§°"], r["æ ‡ä¹¦æè¿°"]])]
        print(f"æœ€ç»ˆæå–åˆ° {len(results)} æ¡å†…å®¹")
        return results

    # ----------- Word åˆåŒï¼ˆä¿®å¤ç‰ˆï¼Œå¤„ç†è¡¨æ ¼åˆ†å‰²é—®é¢˜ï¼‰ -----------
    def extract_tables_from_word_contract(self, docx_path: str) -> List[Dict]:
        data = []
        found_quotation_section = False
        current_headers = None
        doc = Document(docx_path)
        
        # å…ˆæ£€æŸ¥æ•´ä¸ªæ–‡æ¡£æ˜¯å¦åŒ…å«åˆ†é¡¹æŠ¥ä»·è¡¨
        has_quotation_table = False
        for para in doc.paragraphs:
            if "åˆ†é¡¹æŠ¥ä»·è¡¨" in para.text:
                has_quotation_table = True
                break
        
        if not has_quotation_table:
            return data
        
        # å¤„ç†æ‰€æœ‰è¡¨æ ¼
        for table_idx, table in enumerate(doc.tables):
            rows = list(table.rows)
            if not rows:
                continue
            
            # æ£€æŸ¥è¡¨å¤´
            headers = [cell.text.strip().replace('\n', '') for cell in rows[0].cells]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡è¡¨æ ¼ï¼ˆä½¿ç”¨è‡ªå®šä¹‰è¡¨å¤´æˆ–é»˜è®¤è¡¨å¤´ï¼‰
            if self._is_target_table_custom(headers):
                current_headers = headers
                found_quotation_section = True
                start_row = 1
                print(f"âœ… æ‰¾åˆ°åŒ¹é…çš„è¡¨æ ¼ï¼Œè¡¨å¤´ï¼š{headers}")
            elif current_headers and found_quotation_section:
                start_row = 0
            else:
                continue
                
            # å¤„ç†æ•°æ®è¡Œ
            for row_idx, row in enumerate(rows[start_row:], start=start_row):
                row_data = {}
                cells = row.cells
                
                # å¤„ç†åˆå¹¶å•å…ƒæ ¼çš„æƒ…å†µ
                for idx, header in enumerate(current_headers):
                    if idx < len(cells):
                        cell_text = cells[idx].text.strip()
                        row_data[header] = cell_text
                    else:
                        row_data[header] = ''
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
                has_data = False
                
                # æ£€æŸ¥åºå·å­—æ®µ
                for header in current_headers:
                    if 'åºå·' in header and row_data.get(header, '').strip():
                        # å¦‚æœåºå·æ˜¯æ•°å­—ï¼Œè®¤ä¸ºæœ‰æ•ˆ
                        try:
                            int(row_data[header])
                            has_data = True
                            break
                        except ValueError:
                            # å¦‚æœä¸æ˜¯æ•°å­—ï¼Œæ£€æŸ¥å…¶ä»–å­—æ®µ
                            pass
                
                # å¦‚æœåºå·ä¸æ˜¯æ•°å­—ï¼Œæ£€æŸ¥å…¶ä»–å…³é”®å­—æ®µ
                if not has_data:
                    # ä½¿ç”¨è‡ªå®šä¹‰è¡¨å¤´æˆ–é»˜è®¤è¡¨å¤´è¿›è¡Œæ£€æŸ¥
                    key_fields = self._get_key_fields_for_check()
                    for field in key_fields:
                        for header in current_headers:
                            if field in header and row_data.get(header, '').strip():
                                has_data = True
                                break
                        if has_data:
                            break
                
                # å¦‚æœå…³é”®å­—æ®µéƒ½æ²¡æœ‰ï¼Œå†æ£€æŸ¥å…¶ä»–å­—æ®µ
                if not has_data:
                    has_data = any(row_data.get(header, '').strip() for header in current_headers)
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if has_data:
                    mapped = self._map_word_row_custom(row_data, docx_path)
                    
                    # æ–°å¢ï¼šæ£€æŸ¥é‡å¤å¹¶å¤„ç†
                    if len(data) > 0:
                        # æŸ¥æ‰¾ä¸Šä¸€ä¸ªéç©ºçš„ä¸€çº§æ¨¡å—åç§°
                        last_lvl1 = ""
                        last_lvl2 = ""
                        for i in range(len(data) - 1, -1, -1):
                            if data[i]['ä¸€çº§æ¨¡å—åç§°'].strip():
                                last_lvl1 = data[i]['ä¸€çº§æ¨¡å—åç§°']
                                break
                        for i in range(len(data) - 1, -1, -1):
                            if data[i]['äºŒçº§æ¨¡å—åç§°'].strip():
                                last_lvl2 = data[i]['äºŒçº§æ¨¡å—åç§°']
                                break
                        
                        # æ£€æŸ¥ä¸€çº§æ¨¡å—åç§°æ˜¯å¦é‡å¤
                        if mapped['ä¸€çº§æ¨¡å—åç§°'] == last_lvl1 and mapped['ä¸€çº§æ¨¡å—åç§°']:
                            mapped['ä¸€çº§æ¨¡å—åç§°'] = ''
                        # æ£€æŸ¥äºŒçº§æ¨¡å—åç§°æ˜¯å¦é‡å¤
                        if mapped['äºŒçº§æ¨¡å—åç§°'] == last_lvl2 and mapped['äºŒçº§æ¨¡å—åç§°']:
                            mapped['äºŒçº§æ¨¡å—åç§°'] = ''
                    
                    data.append(mapped)
                else:
                    pass
        
        return data

    def extract_tables_from_word_bid(self, docx_path: str) -> List[Dict]:
        """æå–Wordæ ‡ä¹¦æ–‡ä»¶ä¸­çš„è¡¨æ ¼"""
        # æ ‡ä¹¦æ–‡ä»¶ä½¿ç”¨é»˜è®¤çš„æ˜ å°„é€»è¾‘
        data = []
        found_quotation_section = False
        current_headers = None
        doc = Document(docx_path)
        
        # å…ˆæ£€æŸ¥æ•´ä¸ªæ–‡æ¡£æ˜¯å¦åŒ…å«åˆ†é¡¹æŠ¥ä»·è¡¨
        has_quotation_table = False
        for para in doc.paragraphs:
            if "åˆ†é¡¹æŠ¥ä»·è¡¨" in para.text:
                has_quotation_table = True
                break
        
        if not has_quotation_table:
            return data
        
        # å¤„ç†æ‰€æœ‰è¡¨æ ¼
        for table_idx, table in enumerate(doc.tables):
            rows = list(table.rows)
            if not rows:
                continue
            
            # æ£€æŸ¥è¡¨å¤´
            headers = [cell.text.strip().replace('\n', '') for cell in rows[0].cells]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡è¡¨æ ¼
            if self._is_target_table(headers):
                current_headers = headers
                found_quotation_section = True
                start_row = 1
            elif current_headers and found_quotation_section:
                start_row = 0
            else:
                continue
            
            # å¤„ç†æ•°æ®è¡Œ
            for row_idx, row in enumerate(rows[start_row:], start=start_row):
                row_data = {}
                cells = row.cells
                
                # å¤„ç†åˆå¹¶å•å…ƒæ ¼çš„æƒ…å†µ
                for idx, header in enumerate(current_headers):
                    if idx < len(cells):
                        cell_text = cells[idx].text.strip()
                        row_data[header] = cell_text
                    else:
                        row_data[header] = ''
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
                has_data = False
                
                # æ£€æŸ¥åºå·å­—æ®µ
                for header in current_headers:
                    if 'åºå·' in header and row_data.get(header, '').strip():
                        # å¦‚æœåºå·æ˜¯æ•°å­—ï¼Œè®¤ä¸ºæœ‰æ•ˆ
                        try:
                            int(row_data[header])
                            has_data = True
                            break
                        except ValueError:
                            # å¦‚æœä¸æ˜¯æ•°å­—ï¼Œæ£€æŸ¥å…¶ä»–å­—æ®µ
                            pass
                
                # å¦‚æœåºå·ä¸æ˜¯æ•°å­—ï¼Œæ£€æŸ¥å…¶ä»–å…³é”®å­—æ®µ
                if not has_data:
                    key_fields = ['åŠŸèƒ½æè¿°', 'ä¸‰çº§æ¨¡å—', 'åŠŸèƒ½æ¨¡å—', 'åŠŸèƒ½å­é¡¹']
                    for field in key_fields:
                        for header in current_headers:
                            if field in header and row_data.get(header, '').strip():
                                has_data = True
                                break
                        if has_data:
                            break
                
                # å¦‚æœå…³é”®å­—æ®µéƒ½æ²¡æœ‰ï¼Œå†æ£€æŸ¥å…¶ä»–å­—æ®µ
                if not has_data:
                    has_data = any(row_data.get(header, '').strip() for header in current_headers)
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if has_data:
                    mapped = self._map_word_row(row_data, docx_path)
                    data.append(mapped)
                else:
                    pass
        
        return data

    def extract_tables_from_pdf_contract(self, pdf_path: str) -> List[Dict]:
        """æå–PDFåˆåŒæ–‡ä»¶ä¸­çš„è¡¨æ ¼"""
        # PDFåˆåŒæ–‡ä»¶æš‚æ—¶ä½¿ç”¨æ ‡ä¹¦çš„æå–é€»è¾‘
        # å¯ä»¥æ ¹æ®åˆåŒæ–‡ä»¶çš„ç‰¹ç‚¹è¿›è¡Œåç»­ä¼˜åŒ–
        return self.extract_tables_from_pdf_bid(pdf_path)

    def _is_target_table_custom(self, headers: List[str]) -> bool:
        """ä½¿ç”¨è‡ªå®šä¹‰è¡¨å¤´æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡è¡¨æ ¼"""
        if self.custom_headers:
            # ä½¿ç”¨è‡ªå®šä¹‰è¡¨å¤´
            target_headers = list(self.custom_headers.keys())
        else:
            # ä½¿ç”¨é»˜è®¤è¡¨å¤´
            target_headers = list(self.target_columns.keys())
        
        found_headers = []
        
        # é¢„å¤„ç†ç›®æ ‡å­—æ®µåï¼Œå»æ‰æ¢è¡Œç¬¦
        normalized_target_headers = {}
        for target in target_headers:
            normalized_target = target.replace('\n', '').replace('\\n', '')
            normalized_target_headers[normalized_target] = target
        
        for normalized_target, original_target in normalized_target_headers.items():
            for header_cell in headers:
                # å¯¹å®é™…å­—æ®µåä¹Ÿè¿›è¡Œé¢„å¤„ç†
                normalized_header = header_cell.replace('\n', '').replace('\\n', '')
                if normalized_target in normalized_header:
                    found_headers.append(original_target)
                    break
        
        return len(found_headers) >= 2

    def _get_key_fields_for_check(self) -> List[str]:
        """è·å–ç”¨äºæ£€æŸ¥çš„å…³é”®å­—æ®µåˆ—è¡¨"""
        if self.custom_headers:
            # ä½¿ç”¨è‡ªå®šä¹‰è¡¨å¤´
            return list(self.custom_headers.keys())
        else:
            # ä½¿ç”¨é»˜è®¤è¡¨å¤´
            return ['åŠŸèƒ½æè¿°', 'ä¸‰çº§æ¨¡å—', 'åŠŸèƒ½æ¨¡å—', 'åŠŸèƒ½å­é¡¹']

    def _map_word_row_custom(self, row_data: Dict, source_file: str) -> Dict:
        """ä½¿ç”¨è‡ªå®šä¹‰è¡¨å¤´æ˜ å°„Wordè¡Œæ•°æ®"""
        if self.custom_headers:
            # ä½¿ç”¨è‡ªå®šä¹‰è¡¨å¤´æ˜ å°„
            mapped_data = {}
            for header, value in row_data.items():
                for custom_header, standard_field in self.custom_headers.items():
                    if custom_header in header:
                        mapped_data[standard_field] = value
                        break
            
            # æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å®é™…å†…å®¹ï¼Œé¿å…é‡å¤
            lvl1_value = mapped_data.get('ä¸€çº§æ¨¡å—åç§°', '')
            lvl2_value = mapped_data.get('äºŒçº§æ¨¡å—åç§°', '')
            lvl3_value = mapped_data.get('ä¸‰çº§æ¨¡å—åç§°', '')
            desc_value = mapped_data.get('åŠŸèƒ½æè¿°', mapped_data.get('åˆåŒæè¿°', ''))
            
            # æ–°å¢ï¼šæ•°æ®æ¸…æ´—å‡½æ•°
            def clean_module_name(text):
                """æ¸…æ´—æ¨¡å—åç§°ï¼Œå»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œç¬¦"""
                if not text:
                    return ''
                # å»é™¤æ¢è¡Œç¬¦ã€åˆ¶è¡¨ç¬¦ç­‰
                cleaned = text.replace('\n', '').replace('\r', '').replace('\t', '')
                # å»é™¤å¤šä½™ç©ºæ ¼ï¼ˆåŒ…æ‹¬å…¨è§’ç©ºæ ¼ï¼‰
                cleaned = re.sub(r'\s+', ' ', cleaned)
                # å»é™¤é¦–å°¾ç©ºæ ¼
                cleaned = cleaned.strip()
                return cleaned
            
            # æ¸…æ´—å„çº§æ¨¡å—åç§°
            lvl1_cleaned = clean_module_name(lvl1_value)
            lvl2_cleaned = clean_module_name(lvl2_value)
            lvl3_cleaned = clean_module_name(lvl3_value)
            desc_cleaned = clean_module_name(desc_value)
            
            # åªæœ‰å½“æœ‰å®é™…å†…å®¹æ—¶æ‰å¡«å……ï¼Œå¦åˆ™ç•™ç©º
            mapped = {
                'ä¸€çº§æ¨¡å—åç§°': lvl1_cleaned if lvl1_cleaned else '',
                'äºŒçº§æ¨¡å—åç§°': lvl2_cleaned if lvl2_cleaned else '',
                'ä¸‰çº§æ¨¡å—åç§°': lvl3_cleaned if lvl3_cleaned else '',
                'åŠŸèƒ½æè¿°': desc_cleaned if desc_cleaned else '',  # æ”¯æŒåŠŸèƒ½æè¿°å’ŒåˆåŒæè¿°
                'æ ‡ä¹¦æè¿°': '',
                'åˆåŒæè¿°': clean_module_name(mapped_data.get('åˆåŒæè¿°', '')),
                'æ¥æºæ–‡ä»¶': os.path.basename(source_file),
                # 'é¡µç ': 'Wordæ–‡æ¡£'
            }
        else:
            # ä½¿ç”¨é»˜è®¤æ˜ å°„
            mapped = self._map_word_row(row_data, source_file)
        
        return mapped

    # ----------- å…¬å…±è¡¨æ ¼å¤„ç† -----------
    def _is_target_table(self, headers: List[str]) -> bool:
        target_headers = list(self.target_columns.keys())
        found_headers = []
        
        # é¢„å¤„ç†ç›®æ ‡å­—æ®µåï¼Œå»æ‰æ¢è¡Œç¬¦
        normalized_target_headers = {}
        for target in target_headers:
            normalized_target = target.replace('\n', '').replace('\\n', '')
            normalized_target_headers[normalized_target] = target
        
        for normalized_target, original_target in normalized_target_headers.items():
            for header_cell in headers:
                # å¯¹å®é™…å­—æ®µåä¹Ÿè¿›è¡Œé¢„å¤„ç†
                normalized_header = header_cell.replace('\n', '').replace('\\n', '')
                if normalized_target in normalized_header:
                    found_headers.append(original_target)
                    break
        
        return len(found_headers) >= 2

    def _process_table(self, table: List[List], headers: List[str], source_file: str, page_num: int) -> List[Dict]:
        processed_data = []
        column_indices = {}
        for target_col, output_col in self.target_columns.items():
            for idx, header in enumerate(headers):
                if target_col in header:
                    column_indices[output_col] = idx
                    break
        start_row = 1 if any(str(cell).strip() for cell in table[0]) else 0
        for row in table[start_row:]:
            if not row or all(not cell for cell in row):
                continue
            row_data = {}
            for output_col, col_idx in column_indices.items():
                if col_idx < len(row):
                    cell_value = str(row[col_idx]).strip() if row[col_idx] else ''
                    row_data[output_col] = cell_value
                else:
                    row_data[output_col] = ''
            if "æ ‡ä¹¦" in source_file:
                row_data['æ ‡ä¹¦æè¿°'] = row_data.get('åŠŸèƒ½æè¿°', '')
                row_data['åˆåŒæè¿°'] = ''
            elif "åˆåŒ" in source_file:
                row_data['åˆåŒæè¿°'] = row_data.get('åŠŸèƒ½æè¿°', '')
                row_data['æ ‡ä¹¦æè¿°'] = ''
            else:
                row_data['æ ‡ä¹¦æè¿°'] = ''
                row_data['åˆåŒæè¿°'] = ''
            row_data['æ¥æºæ–‡ä»¶'] = os.path.basename(source_file)
            row_data['é¡µç '] = page_num + 1
            processed_data.append(row_data)
        return processed_data

    def _map_word_row(self, row_data: Dict, source_file: str) -> Dict:
        # åˆ›å»ºæ ‡å‡†åŒ–å­—æ®µæ˜ å°„
        field_mapping = {}
        for original_field in ['åŠŸèƒ½æ¨¡å—', 'åŠŸèƒ½å­é¡¹', 'ä¸‰çº§æ¨¡å—', 'åŠŸèƒ½æè¿°']:
            normalized_field = original_field.replace('\n', '').replace('\\n', '')
            field_mapping[normalized_field] = original_field
        
        # æŸ¥æ‰¾åŒ¹é…çš„å­—æ®µ
        mapped_data = {}
        for header, value in row_data.items():
            normalized_header = header.replace('\n', '').replace('\\n', '')
            for normalized_field, original_field in field_mapping.items():
                if normalized_field in normalized_header:
                    mapped_data[original_field] = value
                    break
        
        mapped = {
            'ä¸€çº§æ¨¡å—åç§°': mapped_data.get('åŠŸèƒ½æ¨¡å—', ''),
            'äºŒçº§æ¨¡å—åç§°': mapped_data.get('åŠŸèƒ½å­é¡¹', ''),
            'ä¸‰çº§æ¨¡å—åç§°': mapped_data.get('ä¸‰çº§æ¨¡å—', ''),
            'åŠŸèƒ½æè¿°': mapped_data.get('åŠŸèƒ½æè¿°', ''),
            'æ ‡ä¹¦æè¿°': '',
            'åˆåŒæè¿°': '',
            'æ¥æºæ–‡ä»¶': os.path.basename(source_file),
            # 'é¡µç ': 'Wordæ–‡æ¡£'
        }
        
        if "æ ‡ä¹¦" in source_file:
            mapped['æ ‡ä¹¦æè¿°'] = mapped['åŠŸèƒ½æè¿°']
        elif "åˆåŒ" in source_file:
            mapped['åˆåŒæè¿°'] = mapped['åŠŸèƒ½æè¿°']
        return mapped

    def _merge_paragraphs(self, desc_lines):
        """åˆå¹¶è‡ªç„¶æ®µ"""
        desc_paragraphs = []
        current_para = []
        for line in desc_lines:
            if not line.strip():
                if current_para:
                    desc_paragraphs.append(''.join(current_para))
                    current_para = []
            else:
                current_para.append(line.strip())
        if current_para:
            desc_paragraphs.append(''.join(current_para))
        return desc_paragraphs

    def _clean_extracted_data(self, data: List[Dict]) -> List[Dict]:
        """æ¸…ç†æå–çš„æ•°æ®ï¼Œè¿‡æ»¤æ— æ•ˆå†…å®¹"""
        cleaned_data = []
        
        for item in data:
            # æ£€æŸ¥æ˜¯å¦ä¸ºé¡µç ä¿¡æ¯
            def is_page_content(text):
                if not text:
                    return False
                page_indicators = ['ç¬¬', 'é¡µ', 'Page', 'page']
                return any(indicator in str(text) for indicator in page_indicators)
            
            # æ¸…ç†å„å­—æ®µ
            cleaned_item = {}
            for key, value in item.items():
                if is_page_content(value):
                    print(f"DEBUG: è¿‡æ»¤é¡µç å†…å®¹ '{value}' ä»å­—æ®µ '{key}'")
                    cleaned_item[key] = ""
                else:
                    cleaned_item[key] = value
            
            # åªä¿ç•™æœ‰æ•ˆæ•°æ®
            if any([cleaned_item.get("ä¸€çº§æ¨¡å—åç§°"), cleaned_item.get("äºŒçº§æ¨¡å—åç§°"), 
                   cleaned_item.get("ä¸‰çº§æ¨¡å—åç§°"), cleaned_item.get("æ ‡ä¹¦æè¿°")]):
                cleaned_data.append(cleaned_item)
        
        return cleaned_data

    # ----------- Excelè¾“å‡ºï¼ˆä¿®å¤è¡Œé«˜è®¡ç®—ï¼‰ -----------
    def create_excel_output(self, data: List[Dict], output_path: str, append_mode=False):
        if not data:
            logger.warning("æ²¡æœ‰æ•°æ®éœ€è¦è¾“å‡º")
            return None
        
        # æ–°å¢ï¼šæ™ºèƒ½åˆ†æ®µå¤„ç†å‡½æ•°
        def split_long_description(description, max_length=500):
            """æ™ºèƒ½åˆ†æ®µå¤„ç†é•¿æè¿°"""
            if not description or len(description) <= max_length:
                return [description]
            
            # é¢„å®šä¹‰ç¼–å·æ ¼å¼æ­£åˆ™è¡¨è¾¾å¼
            number_patterns = [
                # ä¸­æ–‡æ•°å­—æ ¼å¼
                r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€',  # ä¸€ã€äºŒã€ä¸‰ã€
                r'[ï¼ˆ(][ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ï¼‰)]',  # ï¼ˆä¸€ï¼‰ï¼ˆäºŒï¼‰
                r'[ï¼ˆ(]\d+[ï¼‰)]',  # ï¼ˆ1ï¼‰ï¼ˆ2ï¼‰
                r'\d+ã€',  # 1ã€2ã€
                r'\d+\.',  # 1.2.3.
                r'\d+ï¼‰',  # 1ï¼‰2ï¼‰
                r'\d+\)',  # 1)2)
                
                # è‹±æ–‡æ•°å­—æ ¼å¼
                r'\d+\.',  # 1.2.3.
                r'[a-z]+\)',  # a)b)c)
                r'[A-Z]+\.',  # A.B.C.
                r'[i]+\)',  # i)ii)iii)
                r'[I]+\.',  # I.II.III.
                
                # ç‰¹æ®Šç¬¦å·
                r'[â€¢â—â—‹â—‡â–¡]',  # é¡¹ç›®ç¬¦å·
                r'ç¬¬ä¸€ã€',  # ç¬¬ä¸€ã€ç¬¬äºŒã€
                r'ç¬¬ä¸€æ¡',  # ç¬¬ä¸€æ¡ç¬¬äºŒæ¡
            ]
            
            # åˆå¹¶æ‰€æœ‰æ¨¡å¼
            combined_pattern = '|'.join(number_patterns)
            
            # æŸ¥æ‰¾æ‰€æœ‰ç¼–å·ä½ç½®
            matches = list(re.finditer(combined_pattern, description))
            
            if not matches:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¼–å·ï¼ŒæŒ‰å¥å·åˆ†å‰²
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', description)
                segments = []
                current_segment = ""
                
                for sentence in sentences:
                    if sentence.strip():
                        if len(current_segment + sentence) <= max_length:
                            current_segment += sentence + "ã€‚"
                        else:
                            if current_segment:
                                segments.append(current_segment.strip())
                            current_segment = sentence + "ã€‚"
                
                if current_segment:
                    segments.append(current_segment.strip())
                
                return segments if segments else [description]
            
            # æ ¹æ®ç¼–å·ä½ç½®åˆ†å‰²
            segments = []
            start_pos = 0
            
            for i, match in enumerate(matches):
                match_start = match.start()
                
                # å¦‚æœå½“å‰æ®µå·²ç»è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œå¼ºåˆ¶åˆ†å‰²
                if match_start - start_pos > max_length:
                    # åœ¨æœ€å¤§é•¿åº¦å¤„å¯»æ‰¾åˆé€‚çš„åˆ†å‰²ç‚¹
                    split_pos = start_pos + max_length
                    # å‘å‰å¯»æ‰¾å¥å·æˆ–é€—å·
                    for j in range(split_pos, start_pos, -1):
                        if description[j] in 'ã€‚ï¼Œï¼ï¼Ÿ':
                            split_pos = j + 1
                            break
                    
                    segments.append(description[start_pos:split_pos].strip())
                    start_pos = split_pos
                
                # å¦‚æœè¿™æ˜¯ç¬¬ä¸€ä¸ªç¼–å·ï¼Œä¿ç•™å‰é¢çš„å†…å®¹
                if i == 0 and match_start > 0:
                    segments.append(description[start_pos:match_start].strip())
                
                # ç¡®å®šå½“å‰æ®µçš„ç»“æŸä½ç½®
                if i < len(matches) - 1:
                    end_pos = matches[i + 1].start()
                else:
                    end_pos = len(description)
                
                # æ·»åŠ å½“å‰ç¼–å·æ®µ
                current_segment = description[match_start:end_pos].strip()
                if current_segment:
                    segments.append(current_segment)
                
                start_pos = end_pos
            
            # å¤„ç†æœ€åä¸€æ®µ
            if start_pos < len(description):
                last_segment = description[start_pos:].strip()
                if last_segment:
                    segments.append(last_segment)
            
            return segments if segments else [description]
        
        # å¤„ç†åŒåæ–‡ä»¶
        def get_unique_filename(filepath):
            if not os.path.exists(filepath):
                return filepath
            directory = os.path.dirname(filepath)
            filename = os.path.basename(filepath)
            name, ext = os.path.splitext(filename)
            counter = 1
            while True:
                new_filename = f"{name}_{counter}{ext}"
                new_filepath = os.path.join(directory, new_filename)
                if not os.path.exists(new_filepath):
                    return new_filepath
                counter += 1
        
        # æ¸…ç†æ•°æ®ä¸­çš„éæ³•å­—ç¬¦
        def clean_cell_value(value):
            if value is None:
                return ""
            if isinstance(value, str):
                cleaned = ""
                for char in value:
                    if ord(char) < 32 and char not in '\t\n\r':
                        continue
                    cleaned += char
                return cleaned.strip()
            return str(value)
        
        # æ¸…ç†æ‰€æœ‰æ•°æ®å¹¶è¿›è¡Œæ™ºèƒ½åˆ†æ®µ
        cleaned_data = []
        for row in data:
            # 1. å…ˆæ¸…ç†æ‰€æœ‰å­—æ®µ
            cleaned_row = {}
            for key, value in row.items():
                cleaned_row[key] = clean_cell_value(value)
            
            # 2. æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦åˆ†æ®µçš„æè¿°å­—æ®µ
            has_segmentation = False
            segments_data = {}
            
            for key in ['æ ‡ä¹¦æè¿°', 'åˆåŒæè¿°', 'åŠŸèƒ½æè¿°']:
                if key in cleaned_row and cleaned_row[key]:
                    segments = split_long_description(cleaned_row[key])
                    if len(segments) > 1:
                        has_segmentation = True
                        segments_data[key] = segments
            
            # 3. æ ¹æ®æ˜¯å¦æœ‰åˆ†æ®µéœ€æ±‚å¤„ç†
            if has_segmentation:
                # æœ‰åˆ†æ®µéœ€æ±‚ï¼Œåˆ›å»ºå¤šè¡Œæ•°æ®
                max_segments = max(len(segments) for segments in segments_data.values())
                
                for i in range(max_segments):
                    new_row = cleaned_row.copy()
                    
                    # å¤„ç†æ¯ä¸ªæè¿°å­—æ®µ
                    for key in ['æ ‡ä¹¦æè¿°', 'åˆåŒæè¿°', 'åŠŸèƒ½æè¿°']:
                        if key in segments_data:
                            if i < len(segments_data[key]):
                                new_row[key] = segments_data[key][i]
                            else:
                                new_row[key] = ''  # å¦‚æœè¿™ä¸ªå­—æ®µçš„æ®µæ•°ä¸å¤Ÿï¼Œè®¾ä¸ºç©º
                    
                    # æ–°å¢ï¼šåˆ†æ®µååªåœ¨ç¬¬ä¸€æ®µä¿ç•™æ¨¡å—åç§°ï¼Œåç»­æ®µæ¸…ç©º
                    if i > 0:
                        # åç»­æ®µæ¸…ç©ºæ¨¡å—åç§°å­—æ®µ
                        new_row['ä¸€çº§æ¨¡å—åç§°'] = ''
                        new_row['äºŒçº§æ¨¡å—åç§°'] = ''
                        new_row['ä¸‰çº§æ¨¡å—åç§°'] = ''
                    
                    cleaned_data.append(new_row)
            else:
                # æ²¡æœ‰åˆ†æ®µéœ€æ±‚ï¼Œç›´æ¥æ·»åŠ åŸè¡Œ
                cleaned_data.append(cleaned_row)
        
        df = pd.DataFrame(cleaned_data)
        
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
        required_columns = ['ä¸€çº§æ¨¡å—åç§°', 'äºŒçº§æ¨¡å—åç§°', 'ä¸‰çº§æ¨¡å—åç§°', 'æ ‡ä¹¦æè¿°', 'åˆåŒæè¿°', 'æ¥æºæ–‡ä»¶', 'é¡µç ']
        for col in required_columns:
            if col not in df.columns:
                df[col] = ''  # æ·»åŠ ç¼ºå¤±çš„åˆ—ï¼Œå¡«å……ç©ºå­—ç¬¦ä¸²
        
        column_order = ['ä¸€çº§æ¨¡å—åç§°', 'äºŒçº§æ¨¡å—åç§°', 'ä¸‰çº§æ¨¡å—åç§°', 'æ ‡ä¹¦æè¿°', 'åˆåŒæè¿°', 'æ¥æºæ–‡ä»¶', 'é¡µç ']
        df = df[column_order]
        
        # è¿½åŠ æ¨¡å¼å¤„ç†
        if append_mode and os.path.exists(output_path):
            try:
                # è¯»å–ç°æœ‰Excelæ–‡ä»¶
                existing_df = pd.read_excel(output_path, sheet_name='åˆ†é¡¹æŠ¥ä»·è¡¨æå–ç»“æœ')
                # åˆå¹¶æ•°æ®
                combined_df = pd.concat([existing_df, df], ignore_index=True)
                df = combined_df
                logger.info(f"å·²è¿½åŠ  {len(data)} æ¡æ–°è®°å½•åˆ°ç°æœ‰æ–‡ä»¶")
            except Exception as e:
                logger.warning(f"è¯»å–ç°æœ‰æ–‡ä»¶å¤±è´¥ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶: {e}")
                append_mode = False        
        
        # è·å–å”¯ä¸€æ–‡ä»¶åï¼ˆä»…åœ¨éè¿½åŠ æ¨¡å¼æ—¶ï¼‰
        if not append_mode:
            unique_output_path = get_unique_filename(output_path)
        else:
            unique_output_path = output_path
        
        with pd.ExcelWriter(unique_output_path, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='åˆ†é¡¹æŠ¥ä»·è¡¨æå–ç»“æœ', index=False)
            worksheet = writer.sheets['åˆ†é¡¹æŠ¥ä»·è¡¨æå–ç»“æœ']
            
            # è®¾ç½®åˆ—å®½
            column_widths = {
                'A': 15, 'B': 15, 'C': 15, 'D': 45, 'E': 45, 'F': 10, 'G': 10
            }
            for col, width in column_widths.items():
                worksheet.column_dimensions[col].width = width
            
            # è®¾ç½®è¡¨å¤´æ ·å¼
            header_font = Font(bold=True, size=12)
            header_alignment = Alignment(horizontal='center', vertical='center')
            for col in range(1, len(column_order) + 1):
                cell = worksheet.cell(row=1, column=col)
                cell.font = header_font
                cell.alignment = header_alignment
            
            # è®¾ç½®æ•°æ®è¡Œæ ·å¼å’Œè¡Œé«˜
            data_alignment = Alignment(horizontal='left', vertical='top', wrap_text=True)
            for row in range(2, len(df) + 2):
                # è®¡ç®—æ¯è¡Œæœ€å¤§å­—ç¬¦æ•°
                max_chars = 0
                for col in range(1, len(column_order) + 1):
                    cell_value = str(worksheet.cell(row=row, column=col).value or '')
                    lines = cell_value.split('\n')
                    for line in lines:
                        line_chars = len(line)
                        if line_chars > 30:
                            needed_lines = (line_chars // 30) + 1
                            max_chars = max(max_chars, needed_lines * 30)
                        else:
                            max_chars = max(max_chars, line_chars)
                
                # è®¡ç®—è¡Œé«˜
                estimated_lines = max(1, (max_chars // 30) + 1)
                row_height = max(20, estimated_lines * 18 + 10)
                worksheet.row_dimensions[row].height = row_height
                
                # è®¾ç½®å•å…ƒæ ¼å¯¹é½æ–¹å¼
                for col in range(1, len(column_order) + 1):
                    cell = worksheet.cell(row=row, column=col)
                    cell.alignment = data_alignment
            
            # è®¾ç½®è¾¹æ¡†
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            for row in worksheet.iter_rows(min_row=1, max_row=len(df) + 1, min_col=1, max_col=len(column_order)):
                for cell in row:
                    cell.border = thin_border
                    
        logger.info(f"Excelæ–‡ä»¶å·²ä¿å­˜åˆ°: {unique_output_path}")
        return unique_output_path

def main():
    extractor = PDFWordTableExtractor()
    files = [
        "æ ‡ä¹¦.PDF",
        "åˆåŒ.pdf",
        "æ ‡ä¹¦.docx",
        "åˆåŒ.docx"
    ]
    all_data = []
    
    # è·å–å”¯ä¸€çš„è¾“å‡ºæ–‡ä»¶åï¼ˆåœ¨å¼€å§‹æ—¶å°±ç¡®å®šï¼‰
    base_output_file = "åˆ†é¡¹æŠ¥ä»·è¡¨æå–ç»“æœ.xlsx"
    
    # è·å–å”¯ä¸€çš„è¾“å‡ºæ–‡ä»¶å
    def get_unique_filename(filepath):
        if not os.path.exists(filepath):
            return filepath
        directory = os.path.dirname(filepath)
        filename = os.path.basename(filepath)
        name, ext = os.path.splitext(filename)
        counter = 1
        while True:
            new_filename = f"{name}_{counter}{ext}"
            new_filepath = os.path.join(directory, new_filename)
            if not os.path.exists(new_filepath):
                return new_filepath
            counter += 1
    
    output_file = get_unique_filename(base_output_file)
    
    # å¤„ç†æ ‡ä¹¦æ–‡ä»¶
    bid_files = [f for f in files if "æ ‡ä¹¦" in f and os.path.exists(f)]
    contract_files = [f for f in files if "åˆåŒ" in f and os.path.exists(f)]
    
    # æ ‡ä¹¦æå–å¾ªç¯
    for bid_file in bid_files:
        ext = os.path.splitext(bid_file)[1].lower()
        file_type = "pdf" if ext == ".pdf" else "docx" if ext == ".docx" else None
        if not file_type:
            continue
            
        logger.info(f"æ­£åœ¨å¤„ç†æ ‡ä¹¦æ–‡ä»¶: {bid_file}")
        
        while True:
            # æå–æ ‡ä¹¦æ•°æ®
            bid_data = extractor.extract_tables(bid_file, file_type)
            
            if bid_data:
                print(f"\nğŸ“Š å½“å‰æå–åˆ° {len(bid_data)} æ¡æ ‡ä¹¦è®°å½•")
                
                all_data.extend(bid_data)  # æ·»åŠ åˆ°æ€»æ•°æ®
                print(f"ğŸ“Š æœ‰æ•ˆæ•°æ®: {len(bid_data)} æ¡")
                
                # è¯¢é—®æ˜¯å¦ç»§ç»­æå–
                while True:
                    choice = input("\næ˜¯å¦ç»§ç»­æå–æ ‡ä¹¦ï¼Ÿ(y/n): ").strip().lower()
                    if choice in ['y', 'n']:
                        break
                    print("è¯·è¾“å…¥ y æˆ– n")
                
                if choice == 'n':
                    break
                else:
                    print("\nè¯·é‡æ–°è¾“å…¥ç¼–å·æ ·ä¾‹è¿›è¡Œä¸‹ä¸€è½®æå–...")
                    continue
            else:
                print(f"\nâŒ åœ¨æ–‡ä»¶ {bid_file} ä¸­æœªæ‰¾åˆ°åˆ†é¡¹æŠ¥ä»·è¡¨")
                break
    
    # å¤„ç†åˆåŒæ–‡ä»¶
    for contract_file in contract_files:
        ext = os.path.splitext(contract_file)[1].lower()
        file_type = "pdf" if ext == ".pdf" else "docx" if ext == ".docx" else None
        if not file_type:
            continue
            
        logger.info(f"æ­£åœ¨å¤„ç†åˆåŒæ–‡ä»¶: {contract_file}")
        
        # å¯¹äºWordåˆåŒæ–‡ä»¶ï¼Œæç¤ºç”¨æˆ·è®¾ç½®è¡¨å¤´
        if file_type == "docx" and "åˆåŒ" in contract_file:
            print(f"\nğŸ“‹ å³å°†å¤„ç†WordåˆåŒæ–‡ä»¶: {contract_file}")
            print("è¯·æ ¹æ®Wordæ–‡æ¡£ä¸­çš„å®é™…è¡¨å¤´è®¾ç½®å­—æ®µæ˜ å°„...")
        
        contract_data = extractor.extract_tables(contract_file, file_type)
        if contract_data:
            all_data.extend(contract_data)
            print(f"\nğŸ“Š åˆåŒæ–‡ä»¶æå–åˆ° {len(contract_data)} æ¡è®°å½•")
    
    # ä¿å­˜æ‰€æœ‰æ•°æ®åˆ°ä¸€ä¸ªExcelæ–‡ä»¶
    if all_data:
        actual_output_file = extractor.create_excel_output(all_data, output_file, append_mode=False)
        if actual_output_file:
            print(f"\nâœ… æå–å®Œæˆï¼å…±æå– {len(all_data)} æ¡è®°å½•")
            print(f"ğŸ“ ç»“æœæ–‡ä»¶ï¼š{actual_output_file}")
        else:
            print("\nâŒ ä¿å­˜æ–‡ä»¶å¤±è´¥")
    else:
        print("\nâŒ æœªæ‰¾åˆ°åˆ†é¡¹æŠ¥ä»·è¡¨ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("1. æ–‡ä»¶æ˜¯å¦åŒ…å«'åˆ†é¡¹æŠ¥ä»·è¡¨'å­—æ ·")
        print("2. è¡¨æ ¼æ˜¯å¦åŒ…å«'åŠŸèƒ½æ¨¡å—'ã€'åŠŸèƒ½å­é¡¹'ã€'ä¸‰çº§æ¨¡å—'ç­‰åˆ—")
        print("3. å¯¹äºWordåˆåŒæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è¡¨å¤´è®¾ç½®æ˜¯å¦æ­£ç¡®")

if __name__ == "__main__":
    main()